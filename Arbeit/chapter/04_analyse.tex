\chapter{Analyse der Algorithmen}
\label{analyse}

% TODO: Einleitungssatz

\section{Selektion}
{
	Zur Auswahl standen die fünf Algorithmen \cite{2000_Di}, \cite{2001_Go}, \cite{2001_BeatThis}, \cite{2009_DaPlSt}, \cite{2011_PlRoSt}.
	Daraus sollten drei Algorithmen für den Vergleich ausgewählt werden.

	Der Algorithmus von~\cite{2001_Go} sollte ursprünglich dabei sein,
		da er viele eigene innovative Lösungsansätze bietet,
		die in keinem der anderen Paper wiedergefunden wurden.
	Leider konnten wir diesen Algorithmus nicht implementieren,
		da im Paper die Funktionsweise der Einsatzdetektion und des Onset-Time-Vectorizers
		nicht detailliert genug beschrieben werden.
	Da alle anderen Paper statt Einsatzdetektionsvektoren eine Einsatzdetektionsfunktion (ODF von engl. onset detection function) verwenden,
		konnten wir auch nicht diesen Teil des Algorithmus mit der ODF eines anderen Papers austauschen.
	Auch ältere Arbeiten von Masataka Goto (\cite{1994_GoMu}, \cite{1995_GoMu1}, \cite{1996_GoMu}, \cite{1997_GoMu2}),
		welche dieselbe Einsatzdetektion verwenden,
		enthalten keine ausreichenden Informationen über deren Funktionsweise.

	Der Algorithmus von~\cite{2000_Di} wurde ebenfalls für den Vergleih in Betracht gezogen,
		da er einen komplett anderen Ansatz verfolgt als die anderen,
		basierend auf Häufigkeiten von Inter-Onset-Intervallen.
	Leider fehlen auch hier Details,
		die zur Implementierung notwendig sind.

	So bleiben nur noch drei Algorithmen übrig (\cite{2001_BeatThis}, \cite{2009_DaPlSt} und \cite{2011_PlRoSt}).
	Diese basieren alle auf Kammfilter und sind bis auf \cite{2001_BeatThis} noch relativ aktuell.
}

\section{Funktionsweise}
{
	In diesem Abschnitt wird die Funktionsweise der verwendeten Algorithmen im Detail erklärt.
	Dabei werden die für diese Arbeit angefertigten Implementierungen beschrieben,
		welche den Algorithmen der ursprünglichen Paper entsprechen sollten,
		sich jedoch in Kleinigkeiten unterscheiden können.
	Für die Implementierung wurde die Programmiersprache C++ und die Audioverarbeitungsbibliothek Gamma verwendet.

	\subsubsection*{Mathematische Notation}
	{
		In dieser Arbeit werden Subskripte als Indices für Zeitreihen, Listen, Matrizen oder sonstige Arrays genutzt,
			wie z. B. $d_t$.
		% TODO: Sachen wie z. B. überall einheitlich
		Manchmal gibt es mehrere Versionen einer Variable,
			beispielsweise $\tau_\text{alt}$ und $\tau_\text{neu}$.
		In diesem Fall bestehen die Subskripte aus Wörtern und werden nicht kursiv gedruckt,
			um sie von Index-Subskripten unterscheiden zu können.

		Da alle hier vorgestellten Algorithmen auf einem diskreten Zeitraster arbeiten,
			tauchen bestimmte Zeitvariablen oft in zwei Varianten auf:
		Eine reelle Variable in Sekunden,
			die sich auf den kontinuierlichen Zeitstrahl bezieht
			und eine ganzzahlige Variable,
			die sich auf das diskrete Zeitraster bezieht.
		Dabei wird für die ganzzahlige Variable ein ähnlich aussehender griechicher Buchstabe verwendet,
			z. B. $t$ und $\tau$ für Zeitindices
			oder $T$ und $\Upsilon$ für die Beatperiode.
	}

	\subsection{2001 Cheng, Nazer, Uppuluri, Verret - Beat This}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2001_BeatThis} bekommt einen \num{2.57} Sekunden langen Analyserahmen $s_\tau$ als Eingabe,
				welcher \num{113432} PCM-kodierte Audiosamples mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} enthält.
			Die Ausgabe besteht aus einer Temposchätzung $f_\text{final}$ des Musikstücks.
			Da die Ausgabe des Algorithmus nur eine Funktion des eingegebenen Analyserahmens ist,
				jedoch keinen Zustand benötigt oder manipuliert,
				ist es dem Nutzer überlassen wie oft die Tempoeinschätzung aktualisiert wird.
			\begin{equation}
				f_\text{final} = B([s_\tau \mid \tau = 0, ..., 113431])
			\end{equation}
		}

		\subsubsection*{Funktionsweise}
		{
			% 6 Bandpassfilter
			Zuerst wird das Eingangssignal $s_\tau$ in sechs Signale $a_{\tau, k}$ mit $k = 0, ..., 5$ aufgeteilt,
				die jeweils einen anderen Frequenzbereich beinhalten.
			Dazu werden FFT-basierte Bandpassfilter benutzt.
			Das Eingangssignal wird durch eine FFT in ein Frequenzspektrum umgewandelt.
			In diesem Spektrum werden alle unerwünschten Frequenzen auf \num{0} gesetzt
				und dann das Spektrum per IFFT wieder zurück in eine Zeitreihe konvertiert.
			Die Frequenzbereiche der sechs Signale sind
				\SIrange{0}{200}{\hertz}, \SIrange{200}{400}{\hertz},
				\SIrange{400}{800}{\hertz}, \SIrange{800}{1600}{\hertz},
				\SIrange{1600}{3200}{\hertz}, \SIrange{3200}{44100}{\hertz}.
			Die Idee dahinter ist,
				dass verschiedene Instrumentengruppen unabhängig voneinander analysiert werden können.

			% Glättung
			Als nächstes wird jedes der sechs gefilterten Signale geglättet,
				um einen Verlauf der Lautstärke des Signals zu erhalten.
			Dies wird durch die Faltung mit der rechten Seite eines \num{0.4} Sekunden langen Hanning-Fensters $h_\tau$ erzielt.
			Vorher wird das Signal jedoch erst vollweg-gleichgerichtet,
				sodass nur noch positive Samples übrigbleiben.
			\begin{equation}
				b_{\tau, k} = h_\tau * |a_{\tau, k}| \text{\hspace{5mm}für } k = 0, ..., 5
			\end{equation}
			Nach dem Faltungstheorem kann man die Faltung zweier Funktionen als Produkt ihrer fourier-transformierten Signale ausdrücken.
			Da eine effiziente Implementierung einer diskreten Fouriertransformation eine Zeitkomplexität von $O(n\log(n))$ hat,
				kann man die Berechnung dieser Faltung beschleunigen,
				indem man erst die FFT der beiden Signale berechnet,
				diese dann elementweise multipliziert
				und anschlie{\ss}end eine IFFT anwendet.
			Eine naive Implementierung des Faltungsalgorithmus hätte dagegen eine Zeitkomplexität von $O(n^2)$.

			% Differentiation
			Um die Zeitpunkte hervorzuheben,
				an denen die Lautstärke schnell ansteigt,
				werden die sechs Signale differenziert.
			Um nur die Anstiege der Lautstärke zu extrahieren,
				werden anschlie{\ss}end alle negativen Werte auf null gesetzt.
			\begin{align}
				c_{\tau, k} &= \frac{d}{d\tau} b_{\tau, k} \\
				d_{\tau, k} &=
					\begin{cases}
						c_{\tau, k} & \text{falls } c_{\tau, k} > 0 \\
						0           & \text{sonst}
					\end{cases}
					\text{\hspace{5mm}für } k = 0, ..., 5
			\end{align}

			% Kammfilter
			Im nächsten Schritt wird nach dem Tempo des Songs gesucht.
			Dazu wird der Kammfilter $\kappa_{\tau, \psi}$ mit verschiedenen Zahnabständen $\psi$ mit dem Signal $d_{\tau, k}$ gefaltet.
			Ein Kammfilter ist hier eine Abfolge von drei Impulsen (Zähnen) mit gleichem Abstand.
			\begin{equation}
				\kappa_{\tau, \psi} =
					\begin{cases}
						1 & \text{falls } \tau = 0 \text{ oder } \tau = \psi \text{ oder } \tau = 2\psi \\
						0 & \text{sonst}
					\end{cases}
			\end{equation}
			Die Faltung mit einem solchen Kammfilter hat den Effekt,
				dass das Signal dreimal mit jeweils versetztem Anfangszeitpunkt abgespielt wird
				und sich dabei überlagert.
			Wenn der Kammfilter den richtigen Zahnabstand hat (entspricht der aktuellen Beatperiode des Stücks),
				überlagern sich alle Beatanfangszeitpunkte
				und ergeben ein sehr energiereiches Signal.
			Um den richtigen Zahnabstand $\psi$ zu finden,
				werden alle Zahnabstände im Bereich von $\psi_\text{min} = \num{16537}$ bis $\psi_\text{max} = \num{32921}$
				mit einer Schrittweite von \num{512} Samples ausprobiert,
				indem der jeweilige Kammfilter mit den sechs Signalen $d_{\tau, k}$ mit $k = 0, ..., 5$ gefaltet
				und anschlie{\ss}end die Energien der gefalteten Signale berechnet und aufsummiert werden.
			Die Werte für $\psi_\text{min}$ und $\psi_\text{max}$ entsprechen den Beatperioden in Samples von jeweils \SI{160}{BPM} und \SI{80}{BPM}.
			So erhält man eine Energie $E_\psi$ für jeden Zahnabstand.
			\begin{align}
				e_{\tau, k, \psi} &= d_{\tau, k} * \kappa_{\tau, \psi} \\
				E_\psi &= \sum_{k = 0}^5 \sum_\tau {e_{\tau, k, \psi}}^2
			\end{align}
			Für $\psi = \psi_\text{min}, \psi_\text{min} + 512, \psi_\text{min} + 1024, ..., \psi_\text{max}$.
			Der Zahnabstand der Energie mit dem grö{\ss}ten Wert bestimmt die Beatperiode $\Upsilon_\text{final}$ des Musikstücks.
			\begin{align}
				\Upsilon_\text{final} &= \underset{\psi}{\text{argmax}}(E_\psi) \\
				f_\text{final} &= \frac{\SI{44.1}{\kilo\hertz}}{\Upsilon_\text{f}}
			\end{align}
		}
	}

	\subsection{2009 Stark, Davies, Plumbley - Real-Time Beat-Synchronous Analysis of Musical Audio}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2009_DaPlSt} bekommt als Eingabe ein rohes, PCM-kodiertes Audiosignal mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz}.
			Die Samples sind als 32-Bit Gleitkommazahlen kodiert.

			Die Ausgabe besteht aus einer Temposchätzung $f_\text{final}$,
				die alle \num{1.5} Sekunden aktualisiert wird.
			Aus dem Tempo ergibt sich die Beatperiode mit $T_\text{final} = 1 / f_\text{final}$.
			Au{\ss}erdem gibt der Algorithmus eine Beatvorhersage aus,
				die angibt wann der nächste Beat kommt.
			Diese wird jede Beatperiode aktualisiert.
			Wie oft sie tatsächlich aktualisiert wird,
				hängt demnach vom Tempo des Musikstücks ab.
		}

		\subsubsection*{Funktionsweise}
		{
			% STFT und ODF
			Genau wie~\cite{2011_PlRoSt},
				nutzt auch dieser Algorithmus die komplexe Spektraldifferenzfunktion von~\cite{2004_BeDaDuSa}
				als Einsatzdetektionsfunktion (kurz ODF von engl. onset detection function).
			Diese berechnet aus jedem STFT-Frame $p_t$ ein neues ODF-Sample $d_t$.
			\begin{equation}
				d_t = d(p_t)
			\end{equation}
			Für die Kurzzeit-Fouriertransformation wurde ein Von-Hann-Fenster mit einer Breite von \num{1024} und eine Schrittweite von \num{512} verwendet.
			Bei einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} entsteht so ein neuer STFT-Frame
				und somit auch ein neues ODF-Sample
				alle $512 / \SI{44.1}{\kilo\hertz} = \SI{11.61}{\milli\second}$.
			Zeitreihen wie $d_t$ können auf zwei Art und Weisen indexiert werden.
			Entweder mit der tatsächlichen Zeit $t$ in Sekunden
				oder mit einem ganzzahligen Zeitindex $\tau$,
				bei dem eine Einheit \SI{11.61}{\milli\second} entspricht
				($t = \SI{11.61}{\milli\second} \cdot \tau$).
			Im Folgenden werden alle Zeitreihen mit $\tau$ statt $t$ indexiert,
				da die Implementierung intern auch nur mit Zeiteinheiten von \SI{11.61}{\milli\second} arbeitet.
			Auch Beatperioden werden mit $\Upsilon$ statt $T$ angegeben ($T = \SI{11.61}{\milli\second} \cdot \Upsilon$).

			Der Rest des Algorithmus besteht aus zwei Komponenten:
				Temposchätzung und Beatvorhersage.

			% Temposchätzung
			Zur Temposchätzung wird ein knapp sechs Sekunden langer Analyserahmen $\Gamma_\tau$ der Einsatzdetektionsfunktion gespeichert.
			Dieser ist \num{512} ODF-Samples lang ($512 \cdot \SI{11.61}{\milli\second} = \SI{5.944}{\second} $)
				und wird alle \num{128} ODF-Samples weitergeschoben,
				sodass sich immer \SI{75}{\percent} des aktuellen Analyserahmens mit dem vorherigen überlappen.
			Als nächstes wird der Analyserahmen mit einer gleitenden Mittelwertsfunktion geglättet.
			\begin{equation}
				\bar{\Gamma}_\tau = \text{avg}(\{\Gamma_k \mid \tau - 8 \leq k \leq \tau + 8 \})
				\text{\hspace{5mm}mit\hspace{5mm}} \tau = 0, ..., 511
			\end{equation}
			Dieser Mittelwert $\bar{\Gamma}_\tau$ wird von dem originalen Analyserahmen abgezogen und negative Werte auf null gesetzt.
			So ergibt sich die modifizierte Einsatzdetektionsfunktion $\tilde{\Gamma}_\tau$.
			\begin{equation}
				\tilde{\Gamma}_\tau = \max(\{0, \Gamma_\tau - \bar{\Gamma}_\tau\})
				\text{\hspace{5mm}mit\hspace{5mm}} \tau = 0, ..., 511
			\end{equation}

			% AKF
			Im nächsten Schritt wird die normalisierte Autokorrelationsfunktion $A_l$ berechnet.
			\begin{equation}
				A_l = \frac{\sum_{\tau = 0}^{511} \tilde{\Gamma}_\tau \tilde{\Gamma}_{\tau - l}}{512 - l}
				\text{\hspace{5mm}mit\hspace{5mm}} l = 0, ..., 511
			\end{equation}
			Jede Verzögerung $l$ (in ODF-Samples) der Autokorrelationsfunktion entspricht einer bestimmten Beatperiode und einem Tempo.
			Die Autokorrelationsfunktion enthält lokale Maxima an Vielfachen der Beatperiode des korrekten Tempos,
				da sich dort die Einsätze aufeinanderfolgender Beats oder Takte überlagern.

			% Kammfilter
			Um die Beatperiode zu finden,
				werden im nächsten Schritt Kammfilter eingesetzt.
			Ein Kammfilter $\lambda_\Upsilon(l)$ besteht aus vier immer kleiner und breiter werdenden Zähnen,
				welche sich genau an den Vielfachen der Beatperiode $\Upsilon$ des Kammfilters befinden.
			\begin{equation}
				\lambda_\Upsilon(l) =
				\begin{cases}
					\frac{1}{2k - 1} & \text{falls } k \Upsilon - (k - 1) \leq l \leq k \Upsilon + (k - 1) \\
					0 & \text{sonst}
				\end{cases}
				\hspace{5mm}
				\text{\parbox[c]{5cm}{
					mit $k = 1, 2, 3, 4$ \\
					und $\Upsilon = \Upsilon_\text{min}, ..., \Upsilon_\text{max}$
				}}
			\end{equation}
			Die Grenzen $\Upsilon_\text{min}$ und $\Upsilon_\text{max}$ der Beatperiode ergeben sich jeweils aus dem maximalen und minimalen Tempolimit,
				welches für den Algorithmus eingestellt ist.
			% TODO: SIrange fixen
			Für die Implementierung dieser Arbeit wurde
				wie auch im Paper
				das Tempo auf den Bereich von \SIrange{80}{160}{BPM} begrenzt,
				wodurch sich ein Beatperiodenbereich
				von $\Upsilon_\text{min} = \lfloor(\SI{11.61}{\milli\second} \cdot \SI{160}{\per\minute})^{-1}\rfloor = 32$
				bis $\Upsilon_\text{max} = \lceil(\SI{11.61}{\milli\second} \cdot \SI{80}{\per\minute})^{-1}\rceil = 65$
				ergibt.
			Jeder Kammfilter wird dann elementweise mit der Autokorrelationsfunktion und einem tempoabhängigen Gewicht $r(\Upsilon)$ multipliziert
				und anschlie{\ss}end alle Elemente aufsummiert.
			Die Gewichtsfunktion $r(\Upsilon)$ ist eine Rayleigh-Verteilung mit einem Maximum bei \SI{120}{BPM}.
			So werden häufiger vorkommende Tempi bevorzugt.
			Die Rayleigh-Funktion ist wie folgt definiert:
			\begin{equation}
				r(\Upsilon) = \frac{\Upsilon}{\beta^2}e^{\frac{-\tau^2}{2\beta^2}}
			\end{equation}
			wobei die Konstante $\beta$ den höchsten Punkt der Gewichtsfunktion bestimmt.
			Ein Wert von $\beta = 43$ ODF-Samples entspricht hier einem Tempo von
				$(43 \cdot \SI{11.61}{\milli\second})^{-1} = \SI{120}{\per\minute}$.
			\begin{align}
				\Upsilon_\text{final} &=
					\underset{\Upsilon = \Upsilon_\text{min}, ..., \Upsilon_\text{max}}{\text{argmax}}
					\left( \sum_{l = 0}^{511} r(\Upsilon) \lambda_\Upsilon(l) A(l) \right) \\
				f_\text{final} &= (\Upsilon_\text{final} \cdot \SI{11.61}{\milli\second})^{-1}
			\end{align}
			Die Beatperiode des Kammfilters,
				der bei dieser Berechnung die grö{\ss}te Summe hervorbringt,
				wird für die Tempohypothese $f_\text{final}$ genommen.

			% weggelassener Teil ...
			Nach diesem Schritt enthält der originale Algorithmus von~\cite{2009_DaPlSt} noch einen weiteren Schritt,
				der dafür sorgt,
				dass sich die Tempohypothese in jeder Iteration nur lediglich geringfügig ändern kann.
			Dieser Teil wurde für diese Implementierung weggelassen,
				da mit ihm der Algorithmus nach einiger Zeit immer das maximale Tempo von \SI{160}{BPM} ausgab
				und davon nicht mehr abwich. 
			Es stellte sich heraus,
				dass der Algorithmus auch ohne diesen Teil ausreichend stabile Tempohypothesen abgibt,
				obgleich er gelegentlich kurz auf ein anderes Tempo springt.

			% Beatvorhersage
			In der zweiten Komponente des Algorithmus,
				der Beatvorhersage,
				wird der Zeitpunkt des nächsten Beats berechnet.
			Dazu wird eine Score-Funktion $C_\tau$ verwendet,
				welche ein neues Sample für jedes neu eintreffende ODF-Sample berechnet.
			\begin{equation}
				C_\tau = C(d_\tau) =
					(1 - \alpha)d_\tau +
					\alpha \max_{v = -2 \Upsilon_\text{final}, ..., -\Upsilon_\text{final} / 2}(W_1(v) C_{\tau + v})
				\label{eq:score_function}
			\end{equation}
			$\Upsilon_\text{final}$ ist die Beatperiode des geschätzten Tempos
				und kann aus dem vorherigen Teil des Algorithmus, der Tempovorhersage, entnommen werden.
			Zum Start des Algorithmus,
				wenn es noch keine Tempovorhersage gibt,
				wird $\Upsilon_\text{final}$ mit \num{43} initialisiert,
				was einem Tempo von \SI{120}{BPM} entspricht.
			Der Parameter $\alpha = 0.9$ bestimmt den Anteil des rekursiven Teils der Score-Funktion.
			Die Gewichtsfunktion $W_1(v)$ bevorzugt Werte, die genau $\Upsilon_\text{final}$ ODF-Samples in der Vergangenheit liegen.
			\begin{equation}
				W_1(v) = e^{-\frac{1}{2} \left( \eta \log \left( -\frac{v}{\Upsilon_\text{final}} \right) \right)^2}
			\end{equation}
			Der Parameter $\eta = 5$ bestimmt die Breite der glockenförmigen Kurve der Gewichtsfunktion.

			% Score-Funktion in der Zukunft
			Um Beatvorhersagen über die Zukunft machen zu können,
				wird die Score-Funktion noch genau eine Beatperiode weiter in die Zukunft berechnet.
			Dazu wird der Parameter $\alpha$ temporär auf \num{1} gesetzt,
				sodass die linke Seite von Gleichung \eqref{eq:score_function} wegfällt
				und keine ODF-Samples aus der Zukunft benötigt werden.
			Nach dieser Berechnung wird $\alpha$ wieder auf den ursprünglichen Wert gesetzt.
			Dies geschieht jedes Mal,
				wenn die vorherige Beatvorhersage eine halbe Beatperiode in der Vergangenheit liegt.
			Das Maximum der Score-Funktion in der Zukunft gibt den wahrscheinlichsten Zeitpunkt des nächsten Beats an.
			Wenn die vorherige Beatvorhersage eine halbe Beatperiode in der Vergangenheit liegt,
				dann müsste der nächste Beat
				--- wenn sich das Tempo in der Zwischenzeit nicht geändert hat ---
				genau eine halbe Beatperiode in der Zukunft liegen.
			Aus diesem Grund wird die Score-Funktion,
				vor der Suche nach dem Maximum,
				mit einer gau{\ss}schen Gewichtsfunktion $W_2$ multipliziert,
				die Werte, welche genau eine halbe Beatperiode in der Zukunft liegen,
				stärker gewichtet.
			Der nächste Beatzeitpunkt $\tau_\text{b}$ wird demnach folgenderma\{ss}en berechnet.
			\begin{align}
				\tau_\text{b} &= \tau_0 + \underset{v = 1, ..., \Upsilon_\text{final}}{\text{argmax}}(C(\tau_0 + v)W(v)) \\
				W_2(v) &= e^{\frac{-(v - \Upsilon_\text{final} / 2)^2}{2(\Upsilon_\text{final} / 2)^2}}
			\end{align}
			$\tau_0$ ist der aktuelle Zeitpunkt.
		}
	}

	\subsection{2011 Robertson, Stark, Plumbley - Real-Time Visual Beat Tracking Using a Comb Filter Matrix}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2011_PlRoSt} bekommt als Eingabe ein rohes PCM-kodiertes Audiosignal mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz}.
			Die Samples sind als 32-bit Gleitkommazahlen kodiert.
			Die Ausgabe besteht aus Tempo $f_\text{final}$ und Phase $\theta_\text{final}$ der erkannten Beatfolge
				und wird alle \num{11.61} Millisekunden aktualisiert.
			% TODO: Millisekunden einheitlich
			Aus dem Tempo ergibt sich die Beatperiode $T_\text{final} = 1 / f_\text{final}$.
			Um die genaue Bedeutung der Phase zu verstehen,
				kann man die komplette Laufzeit des Algorithmus in $T_\text{final}$ lange Abschnitte unterteilen.
			So sollte sich in jedem Abschnitt ein Schlag befinden.
			Die Phase $\theta_\text{final}$ gibt an,
				wann innerhalb dieser Abschnitte der Schlag kommt (\SIrange{0}{360}{\degree}).
			Dies ist zum einen hilfreich,
				um den genauen Zeitpunkt des nächsten Schlags zu bestimmen,
				zum anderen kann man an langsamen Drifts der Phase die Genauigkeit der Temposchätzung erkennen.
		}

		\subsubsection*{Funktionsweise}
		{
			% STFT und ODF
			Der Algorithmus arbeitet ebenfalls mit einer Einsatzdetektionsfunktion (kurz ODF von engl. onset detection function).
			Tatsächlich verwendet er dieselbe komplexe Spektraldifferenzfunktion $d$ aus~\cite{2004_BeDaDuSa},
				die auch in \cite{2009_DaPlSt} verwendet wurde.
			Diese ODF bekommt einen STFT-Frame $p_t$ als Eingabe und gibt ein ODF-Sample $d_t$ zurück.
			\begin{equation}
				d_t = d(p_t)
			\end{equation}
			Für die Kurzzeit-Fouriertransformation wurde ein Von-Hann-Fenster mit einer Breite von \num{1024} und eine Schrittweite von \num{512} verwendet.
			Bei einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} entsteht so ein neuer STFT-Frame
				und somit auch ein neues ODF-Sample,
				alle $512 / \SI{44.1}{\kilo\hertz} = \SI{11.61}{\milli\second}$.

			% vorverarbeitete ODF
			Im nächsten Schritt werden die ODF-Samples vorverarbeitet.
			Dazu wird zuerst der Median der Einsatzdetektionsfunktion berechnet.
			Da aus~\cite{2011_PlRoSt} nicht hervorgeht,
				über welchen Zeitraum der Median berechnet wird,
				wird in der Implementierung dieser Arbeit
				ein sechs Sekunden langer Analyserahmen der Einsatzdetektionsfunktion gespeichert
				und dieser zur Berechung des Medians genutzt.
			Anders als bei~\cite{2009_DaPlSt} wird hier der Analyserahmen nicht alle \num{1.5} Sekunden,
				sondern nach jedem neuen ODF-Sample weitergeschoben,
				sodass er immer die letzten sechs Sekunden (\num{517} Samples) der Einsatzdetektionsfunktion enthält.
			So wird aus jedem neuen ODF-Sample $d_\tau$ sofort das nächste Sample $v_\tau$ der vorverarbeiteten ODF berechnet.
			\begin{equation}
				v_\tau = v(d_\tau) =
				\begin{cases}
					d_\tau & \text{falls } d_\tau > \text{median} \\
					0    & \text{sonst}
				\end{cases}
			\end{equation}
			Diese vorverarbeitete Einsatzdetektionsfunktion wird im nächsten Schritt genutzt,
				um die Kammfiltermatrix zu aktualisieren.

			% Beschreibung Kammfiltermatrix
			Die Kammfiltermatrix $X_{\Upsilon, x}$ enthält eine Zeile für jede mögliche Temposchätzung, die der Algorithmus abgeben kann.
			Diese werden mit der entsprechenden Beatperiode in ODF-Sample-Dauern indizieren.
			Da der Algorithmus auf einen Tempobereich von \SIrange{80}{160}{BPM} beschränkt ist,
				ergibt sich ein minimaler Zeilenindex von
				$\Upsilon_{\text{min}} = \lfloor(\SI{11.61}{\milli\second} \cdot \SI{160}{\per\minute})^{-1}\rfloor = 32$
				und ein maximaler Zeilenindex von
				$\Upsilon_{\text{max}} = \lceil(\SI{11.61}{\milli\second} \cdot \SI{80}{\per\minute})^{-1}\rceil = 65$.
			Jede Zeile enthält eine Zelle für jeden diskreten Zeitpunkt innerhalb der entsprechenden Beatperiode.
			Diese haben jeweils einen Abstand von einer ODF-Sample-Dauer
				und werden deshalb ebenfalls in dieser Einheit adressiert.
			So ergibt sich für eine bestimmte Zeile $\Upsilon$ ein Zellenindexbereich von $x = 0, ..., \Upsilon - 1$.
			Der Zellenindex $x$ ist direkt mit der Phase $\theta$ korreliert,
				jedoch wird hier eine andere Variable verwendet,
				da $x$ in ODF-Sample-Dauern von $0$ bis $\Upsilon - 1$ angegeben werden kann
				und $\theta$ einen Phasenwinkel von \SIrange{0}{359}{\degree} annehmen kann
				und die Umrechnung der beiden Grö{\ss}en von der Beatperiode $\Upsilon$ abhängt.

			% Kammfiltermatrixaktuelisierung
			Die Kammfiltermatrix wird mit jedem neuen vorverarbeiteten ODF-Sample $v_\tau$ zum Zeitpunkt $\tau$ aktualisiert.
			Dabei wird für jede Zeile $\Upsilon$ die Zelle,
				die dem aktuellen Zeitpunkt $x = \tau \bmod \Upsilon$ entspricht,
				mit der Updateregel
				\begin{equation}
					X_{\Upsilon, x} \leftarrow
						\alpha v_\tau +
						(1 - \alpha) \max_{
							\substack{
								\Upsilon_\text{m} = \Upsilon_{\text{min}}, ..., \Upsilon_{\text{max}} \\
								x_\text{m} = 0, ..., \Upsilon - 1
							}
						}
						(g(\Upsilon, \Upsilon_\text{m}, 3.5) g(x, x_\text{m}, 6) X_{\Upsilon, x})
				\end{equation}
				aktualisiert.
			Die Konstante $\alpha$ ist \num{0.1}
				und $g$ ist eine Gewichtsfunktion,
				die die Form einer gau{\ss}schen Normalverteilung annimmt,
				jedoch immer ein Maximum von \num{1} hat.
			$\sigma$ bestimmt nur die Breite der Glockenkurve,
				jedoch nicht die Höhe wie bei einer gewöhnlichen Normalverteilung.
			\begin{equation}
				g(c, m, \sigma) = e^{-\frac{(c - m)^2}{2\sigma^2}}
			\end{equation}

			% Idee dahinter
			Die Idee hinter dieser Updateregel ist,
				dass sich in der zum richtigen Tempo gehörenden Zeile
				die Peaks der vorverarbeiteten ODF immer wieder an der gleichen Stelle überlagern
				und somit eine Zelle in dieser Zeile einen sehr hohen Wert annimmt,
				während in anderen Zeilen
				wegen des unpassenden Tempos dieser Zeilen
				die Peaks immer auf eine andere Stelle treffen
				und es so nicht schaffen,
				eine einzelne Zelle hochzudrücken.
			Um das geschätzte Tempo und die Phase zu bestimmen,
				kann man nach dem Maximum in der Matrix suchen.
			Bevor das geschieht,
				durchläuft diese jedoch erst einen weiteren Verarbeitungsschritt.

			% Y-Matrix
			Zunächst wird jede Zeile mit einem Rayleigh-Gewicht multipliziert.
			Diese Gewichtsfunktion hat ihr Maximum bei \SI{120}{BPM} und flacht nach au{\ss}en hin ab.
			So werden häufiger vorkommende Tempi bevorzugt.
			Die Rayleigh-Funktion ist wie folgt definiert:
			\begin{equation}
				r(\Upsilon) = \frac{\Upsilon}{\beta^2}e^{\frac{-\Upsilon^2}{2\beta^2}}
			\end{equation}
			wobei die Konstante $\beta$ den höchsten Punkt der Gewichtsfunktion bestimmt.
			Ein Wert von $\beta = 43$ ODF-Samples entspricht hier einem Tempo von
				$(43 \cdot \SI{11.61}{\milli\second})^{-1} = \SI{120}{\per\minute}$.
			Die Zeile des richtigen Tempos hat womöglich eine starke Konzentration an hohen Werten um den Punkt der richtigen Phase herum.
			Damit ist gemeint,
				dass diese Zeile eine niedrigere Entropie hat als andere Zeilen,
				deren Werte gleichmä{\ss}iger über die gesamte Zeile verteilt sind.
			Die Entropie einer Matrixzeile ist durch
				\begin{equation}
					h(\Upsilon) = \sum_{x = 0}^{\Upsilon - 1} -p(\Upsilon, x) log(p(\Upsilon, x))
				\end{equation}
				definiert, wobei
				\begin{equation}
					p(\Upsilon, x) = \frac{X_{\Upsilon, x}}{\sum_{x_i = 0}^{\Upsilon - 1}X_{\Upsilon, x_i}}
				\end{equation}
				als Häufigkeitsverteilung einer Zeile interpretiert werden kann.
			Als nächstes wird in der resultierenden Matrix
				\begin{equation}
					Y_{\Upsilon, x} = \frac{r(\Upsilon)}{h(\Upsilon)}X_{\Upsilon, x}
				\end{equation}
				nach dem Maximum gesucht.
			Der Matrixindex $(\Upsilon_{\text{neu}}, x_{\text{neu}})$ des Maximums gibt das wahrscheinlichste Tempo und die wahrscheinlichste Phase an.

			% Tempoübergänge
			Da das so ermittelte Tempo-Phase-Paar  z. B. bei Unregelmä{\ss}igkeiten in der Musik etwas schwanken kann,
				gibt es noch eine Tempoupdateregel,
				die dafür sorgt,
				dass sich das Tempo und die Phase nur dann ändern können,
				wenn sich entweder die neue Hypothese in der Matrix relativ nah an der alten befindet
				oder sie viel stärker ist als diese.
			Hierfür wird eine Gewichtsfunktion definiert,
				welche Werte in der Nähe der aktuellen Hypothese $(\Upsilon_\text{final}, x_\text{final})$ bevorzugt.
			\begin{equation}
				w(\Upsilon_{\text{neu}}, x_{\text{neu}}) =
					g(\Upsilon_\text{final}, \Upsilon_{\text{neu}}, 4)
					g(x_\text{final}, x_{\text{neu}}, 10)
			\end{equation}
			Die Standartabweichungen von \num{4} und \num{10} wurden durch~\cite{2011_PlRoSt} experimentell ermittelt.
			Die aktuelle Hypothese wird mit folgender Updateregel aktualisiert.
			\begin{equation}
				(\Upsilon_\text{final}, x_\text{final}) \leftarrow
				\begin{cases}
					(\Upsilon_{\text{neu}}, x_{\text{neu}}) &
						\text{falls } w(\Upsilon_{\text{neu}}, x_{\text{neu}}) Y_{\Upsilon_{\text{neu}}, x_{\text{neu}}} >
							Y_{\Upsilon_\text{final}, x_\text{final}} \\
					(\Upsilon_\text{final}, x_\text{final}) &
						\text{sonst}
				\end{cases}
			\end{equation}

			% Schlusssatz
			All in diesem Unterabschnitt dargestellten Berechnungen werden für jedes neue Sample der Einsatzdetektionsfunktion durchgeführt.
			So gibt der Algorithmus alle \SI{11.61}{\milli\second} eine neue Tempo-Phase-Hypothese aus.
		}
	}
}
