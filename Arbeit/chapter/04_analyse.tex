\chapter{Analyse der Algorithmen}
\label{analyse}

\section{Selektion}
{
}

\section{Vergleich}
{
}

\section{Funktionsweise}
{
	% TODO: sagen, dass ich hier meine eigenen Implementierung beschreibe, welche aber dem Paper entsprechen sollte und wenn nicht schreib ichs dazu
	% TODO: vielleicht ein Wort zur Notation verlieren wegen Subscript und Klammern
	% * Subsxript t ist meistens Zeitreihenindex
	% * Subscripte sind meistens Indices für Zeitreihen, Arrays oder Matrizen
	% * manchmal werden Subscripte auch benutzt um verschiedene Versionen einer Variable zu differenzieren
	%   z. B. tau_f und tau_neu --> dann wern sa aber als Wörter geschrieben mit ner Text-Schriftart
	% * Zahlen in Klammern sind Parameter einer Funktion, die iwas mit diesen Zahlen macht
	% TODO: irgendwo erklären was ne ODF ist

	% Man könnte, wenn man noch Wörter braucht, noch viel mehr auf Implementierungsdetails eingehen, wie bestimmte Sachen umgesetzt wurden

	In diesem Abschnitt wird die Funktionsweise der verwendeten Algorithmen im Detail erklärt.
	Dabei werden die, für diese Arbeit angefertigten, Implementierungen beschrieben,
		welche den Algorithmen der ursprünglichen Paper entsprechen sollten,
		sich jedoch in Kleinigkeiten unterscheiden können.
	% TODO: weggelassenen Teil in 2009_DaPlSt erklären und hier schreiben,
	% dass es dann unten gesagt wird, wenn sich doch was signifikantes ändert

	\subsection{2001 Cheng, Nazer, Uppuluri, Verret - Beat This}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2001_BeatThis} bekommt einen \num{2.57} Sekunden langen Analyserahmen $s_\tau$ als Eingabe,
				welcher \num{113432} PCM-kodierte Audiosamples mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} enthält.
			Die Ausgabe besteht aus einer Temposchätzung $f_\text{f}$ des Musikstücks.
			Da die Ausgabe des Algorithmus nur eine Funktion des eingegebenen Anlyserahmens ist,
				jedoch keinen Zustand benötigt oder manipuliert,
				ist es dem Nutzer überlassen,
				wie oft die Tempoeinschätzung aktualisiert wird.
			\begin{equation}
				f_\text{f} = B([s_\tau \mid \tau = 0, ..., 113431])
			\end{equation}
		}

		\subsubsection*{Funktionsweise}
		{
			% 6 Bandpassfilter
			Zuerst wird das Eingangssignal $s_\tau$ in sechs Signale $a_{\tau, k}$ mit $k = 0, ..., 5$ aufgeteilt,
				die jeweils einen anderen Frequenzbereich beinhalten.
			Dazu werden FFT-basierte Bandpassfilter benutzt.
			Das Eingangssignal wird duch eine FFT ein ein Frequenzspektrum umgewandelt.
			In diesem Spektrum werden alle unerwünschten Frequenzen auf \num{0} gesetzt
				und dann das Spektrum per IFFT wieder zurück in eine Zeitreihe konvertiert.
			Die Frequenzbereiche der sechs Signale sind
				\SIrange{0}{200}{\hertz}, \SIrange{200}{400}{\hertz},
				\SIrange{400}{800}{\hertz}, \SIrange{800}{1600}{\hertz},
				\SIrange{1600}{3200}{\hertz}, \SIrange{3200}{44100}{\hertz}.
			Die Idee dahinter ist,
				dass verschiedene Instrumentengruppen unabhängig voneinander analysiert werden können.

			% Glättung
			Als nächstes wird jedes der sechs gefilterten Signale geglättet,
				um einen Verlauf der Lautstärke des Signals zu erhalten.
			Das wird durch die Faltung mit der rechten Seite eines \num{0.4} Sekunden langen Hanning-Fensters $h_\tau$ erziehlt.
			Vorher wird das Signal jedoch erst vollweg-gleichgerichtet,
				sodass nur noch positive Samples übrig bleiben.
			\begin{equation}
				b_{\tau, k} = h_\tau * |a_{\tau, k}| \text{ für } k = 0, ..., 5
			\end{equation}
			Nach dem Faltungstheorem,
				kann man die Faltung zweier Funktionen als Produkt ihrer fouriertransformierten Signale ausdrücken.
			Da eine effiziente Implementierung einer diskreten Fouriertransformation eine Zeitkomplexität von $O(n\log(n))$ hat,
				kann man die Berechnung dieser Faltung beschleunigen,
				indem man erst die FFT der beiden Signale berechnet,
				diese dann elementweise multipliziert
				und anschließend eine IFFT anwendet.
			Eine naive Implementierung des Faltungsalgorithmus hätte dagegen eine Zeitkomplexität von $O(n^2)$.

			% Differentiation
			Um die Zeitpunkte hervorzuheben,
				an denen die Lautstärke schnell ansteigt,
				wo sich also Noteneinsätze befinden,
				werden die sechs Signale differenziert.
			Um nur die Anstiege der Lautstärke zu extrahieren,
				werden anschließend alle negativen Werte auf Null gesetzt.
			\begin{align}
				c_{\tau, k} &= \frac{d}{d\tau} b_{\tau, k} \\
				d_{\tau, k} &=
					\begin{cases}
						c_{\tau, k} & \text{falls } c_{\tau, k} > 0 \\
						0           & \text{sonst}
					\end{cases}
					\text{für } k = 0, ..., 5
			\end{align}

			% Kammfilter
			Im nächsten Schritt suchen wir nach dem Tempo des Songs.
			Dazu falten wir Kammfilter $\kappa_{\tau, z}$ mit verschiedenen Zahnabständen $z$ mit dem Signal $d_{\tau, k}$.
			Ein Kammfilter ist hier eine Abfolge von drei Impulsen (Zähnen) mit gleichem Abstand.
			\begin{equation}
				\kappa_{\tau, z} =
					\begin{cases}
						1 & \text{falls } \tau = 0 \text{ oder } \tau = z \text{ oder } \tau = 2z \\
						0 & \text{sonst}
					\end{cases}
			\end{equation}
			Die Faltung mit solch einem Kammfilter hat den Effekt,
				dass das Signal drei mal mit versetzten Anfangszeitpunkten abgespielt wird
				und sich dabei überlagert.
			Wenn der Kammfilter den richtigen Zahnabstand hat,
				also die aktuelle Beatperiode des Stücks,
				dann überlagern sich alle Beatanfangszeitpunkte
				und ergeben ein sehr energiereiches Signal.
			Um den richtigen Zahnabstand $z$ zu finden,
				werden alle Zahnabstände im Bereich von $z_\text{min} = \num{16537}$ bis $z_\text{max} = \num{32921}$
				mit einer Schrittweite von \num{512} Samples ausprobiert,
				indem der jeweilige Kammfilter mit den sechs Signalen $d_{\tau, k}$ mit $k = 0, ..., 5$ gefaltet
				und anschließend die Energien der gefalteten Signale berechnet und aufsummiert werden.
			Die Werte für $z_\text{min}$ und $z_\text{max}$ entsprechen den Beatperioden in Samples von jeweils \SI{160}{BPM} und \SI{80}{BPM}.
			So erhält man eine Energie $E_z$ für jeden Zahnabstand.
			\begin{align}
				e_{\tau, k, z} &= d_{\tau, k} * \kappa_{\tau, z} \\
				E_z &= \sum_{k = 0}^5 \sum_\tau {e_{\tau, k, z}}^2 \\
			\end{align}
			Die Energie mit dem größten Wert bestimmt $z$ als Beatperiode $\Upsilon_\text{f}$ des Musikstücks.
			\begin{align}
				\Upsilon_\text{f} &= \underset{z}{\text{argmax}}(E_z) \\
				f_\text{f} &= \frac{\SI{44.1}{\kilo\hertz}}{\Upsilon_\text{f}}
			\end{align}
			$z = z_\text{min}, z_\text{min} + 512, z_\text{min} + 1024, ..., z_\text{max}$
		}
	}

	\subsection{2009 Stark, Davies, Plumbley - Real-Time Beat-Synchronous Analysis of Musical Audio}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2009_DaPlSt} bekommt als Eingabe ein rohes, PCM-kodiertes Audiosignal mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz}.
			Die Samples sind als 32-Bit Gleitkommazahlen kodiert.

			Die Ausgabe besteht aus einer Temposchätzung $f_\text{f}$,
				die alle \num{1.5} Sekunden aktualisiert wird.
			Aus dem Tempo ergibt sich die Beatperiode mit $T_\text{f} = 1 / f_\text{f}$.
			Außerdem gibt der Algorithmus eine Beatvorhersage aus,
				die angibt,
				wann der nächste Beat kommt.
			Diese wird jede Beatperiode aktualisiert.
			Wie oft sie tatsächlich aktualisiert wird,
				hängt also vom Tempo des Musikstücks ab.
		}

		\subsubsection*{Funktionsweise}
		{
			% STFT und ODF
			Genau wie~\cite{2011_PlRoSt},
				nutzt auch dieser Algorithmus die komplexen Spektraldifferenzfunktion von~\cite{2004_BeDaDuSa}
				als Einsatzdetektionsfunktion (kurz ODF von engl. onset detection function).
			Diese berechnet aus jedem STFT-Frame $p_t$ eine neues ODF-Sample $d_t$.
			\begin{equation}
				d_t = d(p_t)
			\end{equation}
			Für die Kurzzeit-Fouriertransformation wurde ein Von-Hann-Fenster mit einer Breite von \num{1024} und eine Schrittweite von \num{512} verwendet.
			Bei einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} entsteht so ein neuer STFT-Frame,
				und somit auch ein neues ODF-Sample,
				alle $512 / \SI{44.1}{\kilo\hertz} = \SI{11.61}{\milli\second}$.
			Zeitreihen, wie $d_t$, können auf zwei Art und Weisen indexiert werden.
			Entweder mit der tatsächlichen Zeit $t$ in Sekunden
				oder mit einem ganzzahligen Zeitindex $\tau$,
				bei dem eine Einheit \SI{11.61}{\milli\second} entspricht
				($t = \SI{11.61}{\milli\second} \cdot \tau$).
			Im Folgenden werden alle Zeitreihen mit $\tau$, statt $t$, indexiert,
				da die Implementierung intern auch nur mit Zeiteinheiten von \SI{11.61}{\milli\second} arbeitet.
			Auch Beatperioden werden mit $\Upsilon$ statt $T$ angegeben ($T = \SI{11.61}{\milli\second} \cdot \Upsilon$).


			Der Rest des Algorithmus besteht aus zwei Komponenten:
				der Beatvorhersage und der Temposchätzung.

			% Temposchätzung
			Zur Temposchätzung wird ein knapp \num{6} Sekunden langer Analyserahmen $\Gamma_\tau$ der Einsatzdetektionsfunktion gespeichert.
			Dieser ist \num{512} ODF-Samples lang ($512 \cdot \SI{11.61}{\milli\second} = \SI{5.944}{\second} $)
				und wird alle \num{128} ODF-Samples weitergeschoben,
				sodass sich immer \SI{75}{\percent} des aktuellen Analyserahmens mit dem vorherigen überlappen.
			Als nächstes wird der Analyserahmen mit einer gleitenden Mittelwertsfunktion geglättet.
			\begin{equation}
				\bar{\Gamma}_\tau = \text{avg}(\{\Gamma_k \mid \tau - 8 \leq k \leq \tau + 8 \})
				\text{\hspace{5mm}mit\hspace{5mm}} \tau = 0, ..., 511
			\end{equation}
			Dieser Mittelwert $\bar{\Gamma}_\tau$ wird von dem orignalem Analyserahmen abgezogen und negative Werte auf 0 gesetzt.
			So ergibt sich die modifizierte Einsatzdetektionsfunktion $\tilde{\Gamma}_\tau$.
			\begin{equation}
				\tilde{\Gamma}_\tau = \max(\{0, \Gamma_\tau - \bar{\Gamma}_\tau\})
				\text{\hspace{5mm}mit\hspace{5mm}} \tau = 0, ..., 511
			\end{equation}

			% AKF
			Im nächsten Schritt berechnen wir die normalisierte Autokorrelationsfunktion $A_l$.
			\begin{equation}
				A_l = \frac{\sum_{\tau = 0}^{511} \tilde{\Gamma}_\tau \tilde{\Gamma}_{\tau - l}}{512 - l}
				\text{\hspace{5mm}mit\hspace{5mm}} l = 0, ..., 511
			\end{equation}
			Jede Verzögerung $l$ (in ODF-Samples) der Autokorrelationsfunktion entspricht einer bestimmten Beatperiode und einem Tempo.
			Die Autokorrelationsfunktion enthält lokale Maxima an Vielfachen der Beatperiode des korrekten Tempos,
				da sich dort die Einsätze aufeinanderfolgener Beats oder Takte überlagern.

			% Kammfilter
			Um die Beatperiode zu finden,
				werden im nächsten Schritt Kammfilter eingesetzt.
			Ein Kammfilter $\lambda_\Upsilon(l)$ besteht aus vier immer kleiner und breiter werdenden Zähnen,
				welche sich genau an den Vielfachen der Beatperiode $\Upsilon$ des Kammfilters befinden.
			\begin{equation}
				\lambda_\Upsilon(l) =
				\begin{cases}
					\frac{1}{2k - 1} & \text{falls } k \Upsilon - (k - 1) \leq l \leq k \Upsilon + (k - 1) \\
					0 & \text{sonst}
				\end{cases}
				\hspace{5mm}
				\text{\parbox[c]{5cm}{
					mit $k = 1, 2, 3, 4$ \\
					und $\Upsilon = \Upsilon_\text{min}, ..., \Upsilon_\text{max}$
				}}
			\end{equation}
			Die Grenzen $\Upsilon_\text{min}$ und $\Upsilon_\text{max}$ der Beatperiode ergeben sich jeweils aus dem maximalen und minimalen Tempolimit,
				welches für den Algorithmus eingestellt ist.
			Für die Implementierung dieser Arbeit wurde,
				wie auch im Paper,
				das Tempo auf den Bereich von \SIrange{80}{160}{BPM} begrenzt,
				wodurch sich ein Beatperiodenbereich
				von $\Upsilon_\text{min} = \lfloor(\SI{11.61}{\milli\second} \cdot \SI{160}{\per\minute})^{-1}\rfloor = 32$
				bis $\Upsilon_\text{max} = \lceil(\SI{11.61}{\milli\second} \cdot \SI{80}{\per\minute})^{-1}\rceil = 65$
				ergibt.
			Jeder Kammfilter wird dann elementweise mit der Autokorelationsfunktion und einem tempoabhängigen Gewicht $r(\Upsilon)$ multipliziert
				und anschließend alle Elemente aufsummiert.
			Die Gewichtsfunktion $r(\Upsilon)$ ist eine Rayleigh-Verteilung mit einem Maximum bei \SI{120}{BPM}.
			So werden häufiger vorkommende Tempi, bevorzugt.
			Die Rayleigh-Funktion ist wie folgt definiert:
			\begin{equation}
				r(\Upsilon) = \frac{\Upsilon}{\beta^2}e^{\frac{-\tau^2}{2\beta^2}}
			\end{equation}
			wobei die Konstante $\beta$ den höchsten Punkt der Gewichtsfunktion bestimmt.
			Ein Wert von $\beta = 43$ ODF-Samples entspricht hier einem Tempo von
				$(43 \cdot \SI{11.61}{\milli\second})^{-1} = \SI{120}{\per\minute}$.
			\begin{align}
				\Upsilon_\text{f} &=
					\underset{\Upsilon = \Upsilon_\text{min}, ..., \Upsilon_\text{max}}{\text{argmax}}
					\left( \sum_{l = 0}^{511} r(\Upsilon) \lambda_\Upsilon(l) A(l) \right) \\
				f_\text{f} &= (\Upsilon_\text{f} \cdot \SI{11.61}{\milli\second})^{-1}
			\end{align}
			Die Beatperiode des Kammfilters,
				der bei dieser Berechnung die größte Summe hervorbringt,
				wird für die Tempohypothese $f_\text{f}$ genommen.

			% weggelassener Teil ...

			% Beatvorhersage
			In der zweiten Komponente des Algorithmus,
				der Beatvorhersage,
				wird der Zeitpunkt des nächsten Beats berechnet.
			Dazu wird eine Score-Funktion $C_\tau$ verwendet,
				für welche ein neues Sample für jedes neu eintreffende ODF-Sample berechnet wird.
			\begin{equation}
				C_\tau = C(d_\tau) =
					(1 - \alpha)d_\tau +
					\alpha \max_{v = -2 \Upsilon_\text{f}, ..., -\Upsilon_\text{f} / 2}(W_1(v) C_{\tau + v})
				\label{eq:score_function}
			\end{equation}
			$\Upsilon_\text{f}$ ist die Beatperiode des geschätzten Tempos
				und kann aus dem vorherigen Teil des Algorithmus, der Tempovorhersage, entnommen werden.
			Zum Start des Algorithmus,
				wenn es noch keine Tempovorhersage gibt,
				wird $\Upsilon_\text{f}$ mit \num{43} initialisiert,
				was einem Tempo von \SI{120}{BPM} entspricht.
			Der Parameter $\alpha = 0.9$ bestimmt den Anteil des rekursiven Teils der Score-Funktion.
			Die Gewichtsfunktion $W_1(v)$ bevorzugt Werte, die genau $\Upsilon_\text{f}$ ODF-Samples in der Vergangenheit liegen.
			\begin{equation}
				W_1(v) = e^{-\frac{1}{2} \left( \eta \log \left( -\frac{v}{\tau_\text{f}} \right) \right)^2}
			\end{equation}
			Der Parameter $\eta = 5$ bestimmt Breite der glockenförmigen Kurve der Gewichtsfunktion.

			% Score-Funktion in der Zukunft
			Um Beatvorhersagen über die Zukunft machen zu können,
				wird die Score-Funktion noch genau eine Beatperiode weiter in die Zukunft gebildet.
			Dazu wird der Parameter $\alpha$ temporär auf \num{1} gesetzt,
				sodass die linke Seite von Gleichung \eqref{eq:score_function} wegfällt
				und keine ODF-Samples aus der Zukunft benötigt werden.
			Nach dieser Berechnung wird $\alpha$ wieder auf den ursprünglichen Wert gesetzt.
			Das geschieht jedes Mal,
				wenn die vorherige Beatvorhersage eine halbe Beatperiode in der Vergangenheit liegt.
			Das Maximum der Score-Funktion in der Zukunft gibt den wahrscheinlichsten Zeitpunkt des nächsten Beats an.
			Wenn die vorherige Beatvorhersage eine halbe Beatperiode in der Vergangenheit liegt,
				dann müsste der nächste Beat
				--- wenn sich das Tempo in der Zwischenzeit nicht geändert hat ---
				genau eine halbe Beatperiode in der Zukunft liegen.
			Aus diesem Grund wird die Score-Funktion,
				vor der Suche nach dem Maximum,
				mit einer gaußschen Gewichtsfunktion $W_2$ multipliziert,
				die Werte, welche genau eine halbe Beatperiode in der Zukunft liegen,
				stärker gewichtet.
			Der nächste Beatzeitpunkt $\tau_\text{b}$ wird also wie folgt berechnet.
			\begin{align}
				\tau_\text{b} &= \tau_0 + \underset{v = 1, ..., \Upsilon_\text{f}}{\text{argmax}}(C(\tau_0 + v)W(v)) \\
				W_2(v) &= e^{\frac{-(v - \Upsilon_\text{f} / 2)^2}{2(\Upsilon_\text{f} / 2)^2}}
			\end{align}
			$\tau_0$ ist der aktuelle Zeitpunkt.
		}
	}

	\subsection{2011 Robertson, Stark, Plumbley - Real-Time Visual Beat Tracking Using a Comb Filter Matrix}
	{
		\subsubsection*{Ein- und Ausgabe}
		{
			Der Algorithmus von~\cite{2011_PlRoSt} bekommt als Eingabe ein rohes, PCM-kodiertes Audiosignal mit einer Abtastfrequenz von \SI{44.1}{\kilo\hertz}.
			Die Samples sind als 32-Bit Gleitkommazahlen kodiert.
			Die Ausgabe besteht aus Tempo $\gamma$ und Phase $\theta$ der erkannten Beatfolge
				und wird alle \num{11.61} Millisekunden aktualisiert.
			Aus dem Tempo ergibt sich die Beatperiode $T = 1 / \gamma$.
			Um die genaue Bedeutung der Phase zu verstehen,
				kann man die komplette Laufzeit des Algorithmus in $T$ lange Abschnitte unterteilen.
			So sollte sich in jedem Abschnitt ein Schlag befinden.
			Die Phase $\theta$ gibt an,
				wann innerhalb dieser Abschnitte der Schlag kommt (\SIrange{0}{360}{\degree}).
			Das ist zum Einen Hilfreich,
				um den genauen Zeitpunkt des nächsten Schlags zu bestimmen.
			Zum Anderen kann man an langsamen Drifts der Phase erkennen,
				ob das geschätzte Tempo ein bischen zu langsam oder zu schnell ist.
		}

		\subsubsection*{Funktionsweise}
		{
			% STFT und ODF
			Der Algorithmus  arbeitet ebenfalls mit einer Einsatzdetektionsfunktion (kurz ODF von engl. onset detection function).
			Tatsächlich verwent er sogar dieselbe komplexe Spektraldifferenzfunktion $d$ aus~\cite{2004_BeDaDuSa},
				die auch in \cite{2009_DaPlSt} verwendet wurde.
			Diese ODF bekommt einen STFT-Frame $p_t$ als Eingabe und gibt ein ODF-Sample $d_t$ zurück.
			\begin{equation}
				d_t = d(p_t)
			\end{equation}
			Für die Kurzzeit-Fouriertransformation wurde ein Von-Hann-Fenster mit einer Breite von \num{1024} und eine Schrittweite von \num{512} verwendet.
			Bei einer Abtastfrequenz von \SI{44.1}{\kilo\hertz} entsteht so ein neuer STFT-Frame,
				und somit auch ein neues ODF-Sample,
				alle $512 / \SI{44.1}{\kilo\hertz} = \SI{11.61}{\milli\second}$.

			% vorverarbeitete ODF
			Im nächsten Schritt werden die ODF-Samples vorverarbeitet.
			Dazu wird zuerst der Median der Einsatzdetektionsfunktion berechnet.
			Da aus~\cite{2011_PlRoSt} nicht hervorgeht, über welchen Zeitraum der Median berechnet wird,
				wird in meiner Implementierung,
				wie in~\cite{2009_DaPlSt},
				ein \num{6} Sekunden langer Analyserahmen der Einsatzdetektionsfunktion gespeichert
				und dieser zur Berechung des Medians genutzt.
			Anders als bei~\cite{2009_DaPlSt} wird hier der Analyserahmen nicht alle \num{1.5} Sekunden,
				sondern nach jedem neuen ODF-Sample weitergeschoben,
				sodass er immer die letzten \num{6} Sekunden (\num{517} Samples) der Einsatzdetektionsfunktion enthält.
			So wird aus jedem neuen ODF-Sample $d_t$ sofort das nächste Sample $v_t$ der vorverarbeiteten ODF berechnet.
			\begin{equation}
				v_t = v(d_t) =
				\begin{cases}
					d_t & \text{falls } d_t > \text{median} \\
					0    & \text{sonst}
				\end{cases}
			\end{equation}
			Diese vorverarbeitete Einsatzdetektionsfunktion wird im nächsten Schritt genutzt,
				um die Kammfiltermatrix zu aktualisieren.

			% Beschreibung Kammfiltermatrix
			Die Kammfiltermatrix $X_{\tau, x}$ enthält eine Zeile für jede mögliche Temposchätzung, die der Algorithmus abgeben kann.
			Diese werden mit der entsprechenden Beatperiode in ODF-Sample-Dauern adressiert.
			Da der Algorithmus auf einen Tempobereich von \SIrange{80}{160}{BPM} beschränkt ist,
				ergibt sich ein minimaler Zeilenindex von
				$\tau_{\text{min}} = \lfloor(\SI{11.61}{\milli\second} \cdot \SI{160}{\per\minute})^{-1}\rfloor = 32$
				und ein maximaler Zeilenindex von
				$\tau_{\text{max}} = \lceil(\SI{11.61}{\milli\second} \cdot \SI{80}{\per\minute})^{-1}\rceil = 65$.
			Jede Zeile entählt eine Zelle für jeden diskreten Zeitpunkt innerhalb der entsprechenden Beatperiode.
			Diese haben auch jeweils einen Abstand von einer ODF-Sample-Dauer
				und werden deshalb ebenfalls in dieser Einheit adressiert.
			So ergibt sich für eine bestimmte Zeile $\tau$ ein Zellenindexbereich von $x = 0, ..., \tau - 1$.
			Der Zellenindex $x$ ist direkt mit der Phase $\theta$ korreliert,
				jedoch wird hier eine andere Variable verwendet,
				da $x$ in ODF-Sample-Dauern von $0$ bis $\tau - 1$ ist
				und $\theta$ einen Phasenwinkel in von \SIrange{0}{359}{\degree} ist
				und die Umrechnung der beiden Größen von der Beatperiode $\tau$ abhängt.

			% Kammfiltermatrixaktuelisierung
			Die Kammfiltermatrix wird mit jedem neuen vorverarbeiteten ODF-Sample $v_t$ zum Zeitpunkt $t$ aktualisiert.
			Dabei wird für jede Zeile $\tau$ die Zelle,
				die den aktuellen Zeitpunkt entspricht $x = t \bmod \tau$,
				mit der Updateregel
				\begin{equation}
					X_{\tau, x} \leftarrow
						\alpha v_t +
						(1 - \alpha) \max_{\substack{\tau_m = \tau_{\text{min}}, ..., \tau_{\text{max}} \\ x_m = 0, ..., \tau - 1}}
							(g(\tau, \tau_m, 3.5) g(x, x_m, 6) X_{\tau, x})
				\end{equation}
				aktualisiert.
			Die Konstante $\alpha$ ist \num{0.1}
				und $g$ ist eine Gewichtsfunktion,
				die die Form einer gaußschen Normalverteilung annimmt,
				jedoch immer ein Maximum von \num{1} hat.
			$\sigma$ bestimmt also nur die Breite der Glockenkurve,
				aber nicht die Höhe,
				wie bei einer gewöhnlichen Normalverteilung.
			\begin{equation}
				g(c, m, \sigma) = e^{-\frac{(c - m)^2}{2\sigma^2}}
			\end{equation}

			% Idee dahinter
			Die Idee hinter dieser Updateregel ist,
				dass sich,
				in der zum richtigen Tempo gehörenden Zeile,
				die Peaks der vorverarbeiteten ODF immer wieder an der gleichen Stelle überlagern
				und somit eine Zelle in dieser Zeile einen sehr hohen Wert annimmt,
				während in anderen Zeilen,
				wegen des unpassenden Tempos dieser Zeilen,
				die Peaks immer auf eine andere Stelle treffen
				und es so nicht schaffen eine einzelne Zelle hochzudrücken.
			Um das geschätzte Tempo und die Phase zu bestimmen,
				kann man nach dem Maximum in der Matrix suchen.
			Bevor das geschiet,
				durchläuft diese jedoch erst einen weiteren Verarbeitungsschritt.

			% Y-Matrix
			Zunächst wird jede Zeile mit einem Rayleigh-Gewicht multipliziert.
			Diese Gewichtsfunktion hat ihr Maximum bei \SI{120}{BPM} und flacht nach außen hin ab.
			So werden häufiger vorkommende Tempi, bevorzugt.
			Die Rayleigh-Funktion ist wie folgt definiert:
			\begin{equation}
				r(\tau) = \frac{\tau}{\beta^2}e^{\frac{-\tau^2}{2\beta^2}}
			\end{equation}
			wobei die Konstante $\beta$ den höchsten Punkt der Gewichtsfunktion bestimmt.
			Ein Wert von $\beta = 43$ ODF-Samples entspricht hier einem Tempo von
				$(43 \cdot \SI{11.61}{\milli\second})^{-1} = \SI{120}{\per\minute}$.
			Die Zeile des rightigen Tempos hat wahrscheinlich eine starke Konzentration an hohen Werten um den Punkt der richtigen Phase herum.
			Das bedeutet,
				dass diese Zeile eine niedrigere Entropie hat als andere Zeilen,
				deren Werte gleichmäßiger über die gesamte Zeile verteilt sind.
			Die Entropie einer Matrixzeile ist durch
				\begin{equation}
					h(\tau) = \sum_{x = 0}^{\tau - 1} -p(\tau, x) log(p(\tau, x))
				\end{equation}
				definiert, wobei
				\begin{equation}
					p(\tau, x) = \frac{X_{\tau, x}}{\sum_{x_i = 0}^{\tau - 1}X_{\tau, x_i}}
				\end{equation}
				als Häufigkeitsverteilung einer Zeile interpretiert werden kann.
			Als nächstes wird in der resultierenden Matrix
				\begin{equation}
					Y_{\tau, x} = \frac{r(\tau)}{h(\tau)}X_{\tau, x}
				\end{equation}
				nach dem Maximum gesucht.
			Der Matrixindex $(\tau_{\text{neu}}, x_{\text{neu}})$ des Maximums gibt das wahrscheinlichste Tempo und die wahrscheinlichste Phase an.

			% Tempoübergänge
			Da das so ermittelte Tempo-Phase-Paar  z. B. bei Unregelmäßigkeiten in der Musik etwas hin und her springen kann,
				gibt es noch eine Tempoupdateregel,
				die dafür sorgt,
				dass sich das Tempo und die Phase nur dann ändern können,
				wenn entweder die neue Hypothese sich in der Matrix relativ nah an der alten befindet,
				oder sie viel stärker ist als die alte.
			Hierfür definieren wir eine Gewichtsfunktion,
				welche Werte in der Nähe der aktuellen Hypothese $(\tau_\text{f}, x_\text{f})$ bevorzugt.
			\begin{equation}
				w(\tau_{\text{neu}}, x_{\text{neu}}) =
					g(\tau_\text{f}, \tau_{\text{neu}}, 4)
					g(x_\text{f}, x_{\text{neu}}, 10)
			\end{equation}
			Die Standartabweichungen von \num{4} und \num{10} wurden durch~\cite{2011_PlRoSt} experimentell ermittelt.
			Die aktuelle Hypothese wird mit folgender Updateregel aktuelisiert:
			\begin{equation}
				(\tau_\text{f}, x_\text{f}) \leftarrow
				\begin{cases}
					(\tau_{\text{neu}}, x_{\text{neu}}) &
						\text{falls } w(\tau_{\text{neu}}, x_{\text{neu}}) Y_{\tau_{\text{neu}}, x_{\text{neu}}} >
							Y_{\tau_\text{f}, x_\text{f}} \\
					(\tau_\text{f}, x_\text{f}) &
						\text{sonst}
				\end{cases}
			\end{equation}

			% Schlusssatz
			All diese Berechnungen werden für jedes neue Sample der Einsatzdetektionsfunktion durchgeführt.
			So gibt der Algorithmus alle \SI{11.61}{\milli\second} eine neue Tempo-Phase-Hypothese aus.
		}
	}
}
